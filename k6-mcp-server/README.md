# k6-mcp-server â€“ LangChain LCEL Integration

This server allows you to interact with multiple LLM providers using [LangChain LCEL](https://docs.langchain.com/docs/components/runnables). It supports OpenAI, Azure OpenAI (Microsoft Copilot), Anthropic (Claude), and LLaMA 3 (via Ollama).

## ðŸ”§ Features

- âœ… Use LangChain LCEL for chaining prompt templates and outputs
- âœ… Query different LLMs at runtime (`openai`, `azure`, `anthropic`, `ollama`)
- âœ… Extendable to more providers with minimal effort

...

## License

MIT
